{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora Dataset Challenge - To predict if a pair of questions are duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Quora dataset challenge is about predicting whether two questions have similar meaning or not.It is important for Quora to detect duplicate questions to save space and avoid the hassle of answering the same questions for the users.\n",
    "### The goal of this project is to explore natural language processing techniques and integrate them with neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "import gensim\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "os.chdir(\"C:\\\\Users\\\\aksha\\\\Desktop\\\\quora_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the dataset from a csv file and storing it in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6   6    13    14                                Should I buy tiago?   \n",
       "7   7    15    16                     How can I be a good geologist?   \n",
       "8   8    17    18                    When do you use シ instead of し?   \n",
       "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7          What should I do to be a great geologist?             1  \n",
       "8              When do you use \"&\" instead of \"and\"?             0  \n",
       "9  How do I hack Motorola DCX3400 for free internet?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_data = pd.read_csv('train.csv')\n",
    "quora_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So the dataset contains pair of questions on every row and label whether they are duplicate or not. 1 represents duplicate pair of questions and 0 represents non duplicate questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We do not need the id, qid1, qid2 columns as they do not provide any useful information. Let's drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_data = quora_data.drop(['id','qid1','qid2'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imbalanced datasets are problematic. Let's check if our dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.630802\n",
       "1    0.369198\n",
       "Name: is_duplicate, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_data['is_duplicate'].value_counts()/len(quora_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So the dataset seems imbalanced with 64% of the labels belonging to '0' class. When we split the dataset in test and train sets the problem may even get more serious. So we split the original dataset according to the labels. Then we select all the rows with '1' label and equal number of '0' labels to make the distribution uniform and then shuffle the data. (However in the process I am losing the other '0' label rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_data_positive = quora_data['is_duplicate'] ==1\n",
    "quora_data_negative = quora_data['is_duplicate'] ==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_df_1 = quora_data[quora_data_positive]\n",
    "quora_df_1.reset_index();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_df_2 = quora_data[quora_data_negative][:len(quora_df_1)]\n",
    "quora_df_2.reset_index();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_df = pd.DataFrame()\n",
    "quora_df = quora_df.append(quora_df_1).append(quora_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227636</td>\n",
       "      <td>Should I heat my room with a ceramic tower hea...</td>\n",
       "      <td>How can I keep my room warm without heater?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173323</td>\n",
       "      <td>How much does Arijit Singh charge to sing a song?</td>\n",
       "      <td>Which is an easy Hindi song by Arijit to sing?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276645</td>\n",
       "      <td>What are the best hotels in Rajasthan for stay...</td>\n",
       "      <td>Where can I find best hotels at Rajasthan for ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56091</td>\n",
       "      <td>What the purpose of life on earth?</td>\n",
       "      <td>What is the meaning of life? Whats our purpose...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199525</td>\n",
       "      <td>Which is the best pilot training academy in In...</td>\n",
       "      <td>What are the best commercial pilot training sc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96466</td>\n",
       "      <td>How do aromatherapy diffusers work?</td>\n",
       "      <td>How does aromatherapy help depression?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>213811</td>\n",
       "      <td>Is religion the biggest scam mankind has ever ...</td>\n",
       "      <td>Is religion a scam, and if so, how?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>197533</td>\n",
       "      <td>How can I find a pro bono lawyer?</td>\n",
       "      <td>How do I find a pro bono lawyer?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>228727</td>\n",
       "      <td>Is there a way to learn about literature while...</td>\n",
       "      <td>I am a used car dealer in Uttar Pradesh.I want...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101100</td>\n",
       "      <td>How does NEFT and RTGS differ?</td>\n",
       "      <td>How does NEFT/RTGS work?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                          question1  \\\n",
       "0  227636  Should I heat my room with a ceramic tower hea...   \n",
       "1  173323  How much does Arijit Singh charge to sing a song?   \n",
       "2  276645  What are the best hotels in Rajasthan for stay...   \n",
       "3   56091                 What the purpose of life on earth?   \n",
       "4  199525  Which is the best pilot training academy in In...   \n",
       "5   96466                How do aromatherapy diffusers work?   \n",
       "6  213811  Is religion the biggest scam mankind has ever ...   \n",
       "7  197533                  How can I find a pro bono lawyer?   \n",
       "8  228727  Is there a way to learn about literature while...   \n",
       "9  101100                     How does NEFT and RTGS differ?   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0        How can I keep my room warm without heater?             0  \n",
       "1     Which is an easy Hindi song by Arijit to sing?             0  \n",
       "2  Where can I find best hotels at Rajasthan for ...             1  \n",
       "3  What is the meaning of life? Whats our purpose...             1  \n",
       "4  What are the best commercial pilot training sc...             1  \n",
       "5             How does aromatherapy help depression?             0  \n",
       "6                Is religion a scam, and if so, how?             0  \n",
       "7                   How do I find a pro bono lawyer?             1  \n",
       "8  I am a used car dealer in Uttar Pradesh.I want...             0  \n",
       "9                           How does NEFT/RTGS work?             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_df = shuffle(quora_df)\n",
    "quora_df = quora_df.reset_index()\n",
    "quora_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if there are any missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index           0\n",
       "question1       0\n",
       "question2       2\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the number of missing values is very low I am deleting the rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora_df.dropna(inplace=True)\n",
    "quora_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have cleaned the dataset, we can start creating the features. The first feature that I consider is the difference of word count between the two questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_difference = [abs(len(set(quora_df['question1'][i].lower().split(\" \"))) - len(set(quora_df['question2'][i].lower().split(\" \")))) for i in range(len(quora_df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now most of the questions end with the same last word. So the next feature that I consider is a boolean feature whose value is '1' if the last words of both the questions match or '0' if the last words do not match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_word_check = [ 1 if (quora_df['question1'][i].replace(\"?\",\"\").split(\" \")[-1].lower() == quora_df['question2'][i].replace(\"?\",\"\").split(\" \")[-1].lower()) else 0 for i in range(len(quora_df))  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first word of a question is mostly an interogative word represents the tone of the question such as when,where,which and gives out information if the question is regarding time, place or any object. Two similar questions would have the same tone and generally starts with the same interogative word. \n",
    "### So the next feature is a boolean feacture whose value is '1' if the first word of both the questions match and '0' if they do not match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_word_check =  [ 1 if (quora_df['question1'][i].split(\" \")[0].lower() == quora_df['question2'][i].split(\" \")[0].lower()) else 0 for i in range(len(quora_df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For some of the next features I have removed the stop words and compared the remaining words. However I have not used the inbuilt nltk stop words library as it considers certain important words as stop words such as \"before\",\"after\" etc. So I have created my own stop words list by removing those important words from the inbuilt stop words list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i','me','my','we','our','ours','ourselves', 'you', \"you're\",\"you've\",\"you'll\",\"you'd\",'your','yours','yourself','yourselves','he','him', 'his','himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\",'its', 'itself', 'they', 'them', 'their', 'theirs','themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'of', 'at', 'by', 'to', 'from', 'when', 'where', 'why', 'how', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'don', \"don't\", 'should', \"should've\", 'd', 'll', 'm', 'o', 're', 've', 'y','ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\",'hasn', \"hasn't\" 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the next two cells I have removed stop words from every question and stored the remaining words in a set. So for every question I have a set of important words   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens_question1 = [(set(word_tokenize(question.strip(string.punctuation).lower()))-set(stop_words)) if (len(set(word_tokenize(question.strip(string.punctuation).lower()))-set(stop_words))!=0) else set(word_tokenize(question.strip(string.punctuation).lower()))  for question in quora_df['question1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokens_question2 = [(set(word_tokenize(question.strip(string.punctuation).lower()))-set(stop_words)) if (len(set(word_tokenize(question.strip(string.punctuation).lower()))-set(stop_words))!=0) else set(word_tokenize(question.strip(string.punctuation).lower()))  for question in quora_df['question2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now the next feature that I have considered is the character difference between two questions. I create dictionary of letters and their count for every question. Then I compare the dictionaries of the two questions that are to be compared and find the difference in the count of different characters and sum up the difference. Questions with higher sum generally tend to be different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_difference = []\n",
    "for i in range(len(word_tokens_question1)):\n",
    "    counter_question1 = Counter()\n",
    "    counter_question2 = Counter()\n",
    "    for words in word_tokens_question1[i]:\n",
    "        counter_question1 = counter_question1 + Counter(words)\n",
    "    for words in word_tokens_question2[i]:\n",
    "        counter_question2 = counter_question2 + Counter(words)\n",
    "    character_difference.append(len(((counter_question1 - counter_question2) + (counter_question2 - counter_question1)).values())) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next feature considered is the count of same words in both the questions. Two questions with more number of similar words should be similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_similarity = []\n",
    "for i in range(len(word_tokens_question1)):\n",
    "    #print(i)\n",
    "    word_similarity.append(len((word_tokens_question1[i]) & (word_tokens_question2[i]))/len((word_tokens_question1[i]) | (word_tokens_question2[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have used fuzzy wuzzy library for the next 4 features. FuzzyWuzzy package in python was developed and open-sourced by Seatgeek to tackle the ticket search usecase for their website. Fuzzy string matching is the process of finding strings that match a given pattern approximately (rather than exactly). There are four popular types of fuzzy matching logic supported by fuzzywuzzy package:\n",
    "### 1) Simple Ratio - uses pure Levenshtein Distance based matching \n",
    "### 2) Partial Ratio – matches based on best substrings \n",
    "### 3) Token Sort Ratio – tokenizes the strings and sorts them alphabetically before matching\n",
    "### 4) Token Set Ratio – tokenizes the strings and compared the intersection and remainder \n",
    "### I have used all the above scores as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the ratio score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ratio = []\n",
    "for i in range(len(quora_df)):\n",
    "    #print(i)\n",
    "    simple_ratio.append(fuzz.ratio(quora_df['question1'][i],quora_df['question2'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the partial ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_ratio = []\n",
    "for i in range(len(quora_df)):\n",
    "    #print(i)\n",
    "    partial_ratio.append(fuzz.partial_ratio(quora_df['question1'][i],quora_df['question2'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the token sort ratio score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_sort_ratio = []\n",
    "for i in range(len(quora_df)):\n",
    "    #print(i)\n",
    "    token_sort_ratio.append(fuzz.token_sort_ratio(quora_df['question1'][i],quora_df['question2'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the token set ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_set_ratio = []\n",
    "for i in range(len(quora_df)):\n",
    "    #print(i)\n",
    "    token_set_ratio.append(fuzz.token_set_ratio(quora_df['question1'][i],quora_df['question2'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec is an important NLP technique. Word2vec is a two-layer neural net that processes text. Its input is a text corpus and its output is a set of vectors: feature vectors for words in that corpus. It turns text into a numerical form that deep nets can understand and then the neural network computes similarity between two words based on the corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe is an unsupervised learning algorithm for obtaining vector representations for words developed by Stanford university. I have used file containing pre trained vectors obtained after implementing the algorithm on Wikipedia corpus. The file is 'glove.6B.100d.txt'. I then convert the glove file format into word2vec file format. The word2vec file is stored as 'word2vec_output_file_new'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file_new = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next cell creates a model based on the word2vec embeddings defined in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file_new, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I have used this module to calculate the vectors for every word in a question and sum it up. So I get a vector for every question. Then I calculate the difference vector by taking the difference of the two vectors of the two questions to be compared. If two questions are related then the difference vector elements are supposed to be close to zero in value. Then I sum up the elements of the difference vector. Again lower this value higher are the chances for the two questions to be similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "diff_vec=[]\n",
    "for i in range(len(quora_df)):\n",
    "    #print(i)\n",
    "    #diff_vec.append(0)\n",
    "    sum_j=np.zeros((100,))\n",
    "    for j in (word_tokens_question1[i]):\n",
    "        if (j in model.wv.vocab):\n",
    "            sum_j = sum_j + model[j]\n",
    "    sum_k = np.zeros((100,))   \n",
    "    for k in (word_tokens_question2[i]):\n",
    "        if(k in model.wv.vocab):\n",
    "            sum_k = sum_k + model[k]\n",
    "    diff_vec.append((sum_j-sum_k).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's append the features columns to the dataset dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>character_difference</th>\n",
       "      <th>word_count_difference</th>\n",
       "      <th>last_word_check</th>\n",
       "      <th>first_word_check</th>\n",
       "      <th>word_similarity</th>\n",
       "      <th>simple_ratio</th>\n",
       "      <th>partial_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>word2vec_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>227636</td>\n",
       "      <td>Should I heat my room with a ceramic tower hea...</td>\n",
       "      <td>How can I keep my room warm without heater?</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>45</td>\n",
       "      <td>58</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>28.184022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>173323</td>\n",
       "      <td>How much does Arijit Singh charge to sing a song?</td>\n",
       "      <td>Which is an easy Hindi song by Arijit to sing?</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>58</td>\n",
       "      <td>59</td>\n",
       "      <td>-9.798698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276645</td>\n",
       "      <td>What are the best hotels in Rajasthan for stay...</td>\n",
       "      <td>Where can I find best hotels at Rajasthan for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>83</td>\n",
       "      <td>81</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>6.219662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56091</td>\n",
       "      <td>What the purpose of life on earth?</td>\n",
       "      <td>What is the meaning of life? Whats our purpose...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>56</td>\n",
       "      <td>70</td>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>15.366938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199525</td>\n",
       "      <td>Which is the best pilot training academy in In...</td>\n",
       "      <td>What are the best commercial pilot training sc...</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>79</td>\n",
       "      <td>-0.317527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96466</td>\n",
       "      <td>How do aromatherapy diffusers work?</td>\n",
       "      <td>How does aromatherapy help depression?</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>66</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>65</td>\n",
       "      <td>-2.745762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>213811</td>\n",
       "      <td>Is religion the biggest scam mankind has ever ...</td>\n",
       "      <td>Is religion a scam, and if so, how?</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>49</td>\n",
       "      <td>67</td>\n",
       "      <td>9.255804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>197533</td>\n",
       "      <td>How can I find a pro bono lawyer?</td>\n",
       "      <td>How do I find a pro bono lawyer?</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>92</td>\n",
       "      <td>91</td>\n",
       "      <td>92</td>\n",
       "      <td>95</td>\n",
       "      <td>8.841726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>228727</td>\n",
       "      <td>Is there a way to learn about literature while...</td>\n",
       "      <td>I am a used car dealer in Uttar Pradesh.I want...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>14</td>\n",
       "      <td>30</td>\n",
       "      <td>39</td>\n",
       "      <td>34</td>\n",
       "      <td>-2.702942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101100</td>\n",
       "      <td>How does NEFT and RTGS differ?</td>\n",
       "      <td>How does NEFT/RTGS work?</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>74</td>\n",
       "      <td>75</td>\n",
       "      <td>69</td>\n",
       "      <td>88</td>\n",
       "      <td>-7.135651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                          question1  \\\n",
       "0  227636  Should I heat my room with a ceramic tower hea...   \n",
       "1  173323  How much does Arijit Singh charge to sing a song?   \n",
       "2  276645  What are the best hotels in Rajasthan for stay...   \n",
       "3   56091                 What the purpose of life on earth?   \n",
       "4  199525  Which is the best pilot training academy in In...   \n",
       "5   96466                How do aromatherapy diffusers work?   \n",
       "6  213811  Is religion the biggest scam mankind has ever ...   \n",
       "7  197533                  How can I find a pro bono lawyer?   \n",
       "8  228727  Is there a way to learn about literature while...   \n",
       "9  101100                     How does NEFT and RTGS differ?   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0        How can I keep my room warm without heater?             0   \n",
       "1     Which is an easy Hindi song by Arijit to sing?             0   \n",
       "2  Where can I find best hotels at Rajasthan for ...             1   \n",
       "3  What is the meaning of life? Whats our purpose...             1   \n",
       "4  What are the best commercial pilot training sc...             1   \n",
       "5             How does aromatherapy help depression?             0   \n",
       "6                Is religion a scam, and if so, how?             0   \n",
       "7                   How do I find a pro bono lawyer?             1   \n",
       "8  I am a used car dealer in Uttar Pradesh.I want...             0   \n",
       "9                           How does NEFT/RTGS work?             0   \n",
       "\n",
       "   character_difference  word_count_difference  last_word_check  \\\n",
       "0                    15                      5                0   \n",
       "1                    11                      0                0   \n",
       "2                     2                      1                1   \n",
       "3                    11                      4                1   \n",
       "4                    11                      1                1   \n",
       "5                    11                      0                0   \n",
       "6                    16                      2                0   \n",
       "7                     2                      0                1   \n",
       "8                    18                     14                0   \n",
       "9                     8                      2                0   \n",
       "\n",
       "   first_word_check  word_similarity  simple_ratio  partial_ratio  \\\n",
       "0                 0         0.181818            45             58   \n",
       "1                 0         0.333333            44             44   \n",
       "2                 0         0.777778            83             81   \n",
       "3                 1         0.571429            56             70   \n",
       "4                 0         0.625000            70             66   \n",
       "5                 1         0.142857            66             63   \n",
       "6                 1         0.250000            54             60   \n",
       "7                 1         0.800000            92             91   \n",
       "8                 0         0.038462            14             30   \n",
       "9                 1         0.166667            74             75   \n",
       "\n",
       "   token_sort_ratio  token_set_ratio  word2vec_score  \n",
       "0                46               55       28.184022  \n",
       "1                58               59       -9.798698  \n",
       "2                83               85        6.219662  \n",
       "3                76              100       15.366938  \n",
       "4                70               79       -0.317527  \n",
       "5                62               65       -2.745762  \n",
       "6                49               67        9.255804  \n",
       "7                92               95        8.841726  \n",
       "8                39               34       -2.702942  \n",
       "9                69               88       -7.135651  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora_df['character_difference'] = character_difference\n",
    "quora_df['word_count_difference'] = word_count_difference\n",
    "quora_df['last_word_check'] = last_word_check\n",
    "quora_df['first_word_check'] = first_word_check\n",
    "quora_df['word_similarity'] = word_similarity\n",
    "quora_df['simple_ratio'] = simple_ratio\n",
    "quora_df['partial_ratio'] = partial_ratio\n",
    "quora_df['token_sort_ratio'] = token_sort_ratio\n",
    "quora_df['token_set_ratio'] = token_set_ratio\n",
    "quora_df['word2vec_score'] = diff_vec\n",
    "quora_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that we have our features ready, we can build a neural network and try to train the model on this feature set. \n",
    "### X dataframe contains the training features and Y dataframe contains the labels. Then we create dummy columns to represent duplicate and non duplicate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = quora_df[quora_df.columns[4:14]]\n",
    "Y = quora_df[quora_df.columns[3]]\n",
    "Y = pd.get_dummies(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset into train and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(X,Y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.astype('float32');\n",
    "test_x = test_x.astype('float32');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y = np.reshape(train_y,(train_y.shape[0],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238819, 10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_y = np.reshape(test_y,(test_y.shape[0],1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the no. of dimensions, no. of classes and hidden layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = train_x.shape[1]\n",
    "n_class = train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The weights and biases variables are defined below. They are defined as variables as we need to update them with every iteration in training the neural network. To initialize their values I have used the tf.truncated_normal function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "############new\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.truncated_normal([n_dim,n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1,n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2,n_hidden_3])),\n",
    "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3,n_hidden_4])),\n",
    "    'out': tf.Variable(tf.truncated_normal([n_hidden_4,n_class]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1':tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2':tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3':tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4':tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out':tf.Variable(tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epochs are set to 1000.  An epoch describes the number of times the algorithm processes the entire data set. \n",
    "### Batch size is set to 100. Batch size represents the number of data points that the algorithm processes in every iteration. \n",
    "### The display step just sets the number of epoch at which certain statistics of the model is displayed. \n",
    "### x and y are placeholders for the features and labels data. They are defined as placeholders so that we can assign the  data to it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 1000\n",
    "display_step = 50\n",
    "batch_size = 100\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, n_dim])\n",
    "y = tf.placeholder(\"float\", [None, n_class])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we define out network structure. I have used 4 hidden layers with sigmoid activation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilayer_perceptron(x, weights, biases):\n",
    "    \n",
    "    layer1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    #layer1 = tf.reshape(layer1,[x.shape[0]*n_hidden_1,1])\n",
    "    layer1 = tf.nn.sigmoid(layer1)\n",
    "    \n",
    "    \n",
    "    layer2 = tf.add(tf.matmul(layer1,weights['h2']),biases['b2'])\n",
    "    #layer2 = tf.reshape(layer2,[layer1.shape[0]*n_hidden_2,1])\n",
    "    layer2 = tf.nn.sigmoid(layer2)\n",
    "    \n",
    "    layer3 = tf.add(tf.matmul(layer2,weights['h3']),biases['b3'])\n",
    "    #layer3 = tf.reshape(layer3,[layer2.shape[0]*n_hidden_3,1])\n",
    "    layer3 = tf.nn.sigmoid(layer3)\n",
    "    \n",
    "    layer4 = tf.add(tf.matmul(layer3,weights['h4']),biases['b4'])\n",
    "    #layer4 = tf.reshape(layer4,[layer3.shape[0]*n_hidden_4,1])\n",
    "    layer4 = tf.nn.sigmoid(layer4)\n",
    "    \n",
    "    out_layer = tf.matmul(layer4,weights['out']) + biases['out']\n",
    "    #out_layer = tf.reshape(out_layer,[layer4.shape[0]*n_class,1])\n",
    "    return out_layer                                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The next cell runs the neural network with given input (x, weights and biases) and calculates the values predicted by our model when the data passes through the network once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = multilayer_perceptron(x, weights, biases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we define the cost of our model. I have used the cross entropy loss function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-41-e4601f8c3c82>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predictions, labels=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimizer defines the function to be used to optimize the model (weights and biases) based on the cost. I have used Adam optimizer which is a type of gradient descent algorithm. I have set the learning rate to 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we run our neural network. We start the tensorflow session. The global_variables_initializer initializes our variables (weights and biases) with actual values around zero. Then it runs for the set number of epochs and finally we get the optimized weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "Epoch: 0001 cost= 0.604484250\n",
      "epoch:  1\n",
      "epoch:  2\n",
      "epoch:  3\n",
      "epoch:  4\n",
      "epoch:  5\n",
      "epoch:  6\n",
      "epoch:  7\n",
      "epoch:  8\n",
      "epoch:  9\n",
      "epoch:  10\n",
      "epoch:  11\n",
      "epoch:  12\n",
      "epoch:  13\n",
      "epoch:  14\n",
      "epoch:  15\n",
      "epoch:  16\n",
      "epoch:  17\n",
      "epoch:  18\n",
      "epoch:  19\n",
      "epoch:  20\n",
      "epoch:  21\n",
      "epoch:  22\n",
      "epoch:  23\n",
      "epoch:  24\n",
      "epoch:  25\n",
      "epoch:  26\n",
      "epoch:  27\n",
      "epoch:  28\n",
      "epoch:  29\n",
      "epoch:  30\n",
      "epoch:  31\n",
      "epoch:  32\n",
      "epoch:  33\n",
      "epoch:  34\n",
      "epoch:  35\n",
      "epoch:  36\n",
      "epoch:  37\n",
      "epoch:  38\n",
      "epoch:  39\n",
      "epoch:  40\n",
      "epoch:  41\n",
      "epoch:  42\n",
      "epoch:  43\n",
      "epoch:  44\n",
      "epoch:  45\n",
      "epoch:  46\n",
      "epoch:  47\n",
      "epoch:  48\n",
      "epoch:  49\n",
      "epoch:  50\n",
      "Epoch: 0051 cost= 0.518627671\n",
      "epoch:  51\n",
      "epoch:  52\n",
      "epoch:  53\n",
      "epoch:  54\n",
      "epoch:  55\n",
      "epoch:  56\n",
      "epoch:  57\n",
      "epoch:  58\n",
      "epoch:  59\n",
      "epoch:  60\n",
      "epoch:  61\n",
      "epoch:  62\n",
      "epoch:  63\n",
      "epoch:  64\n",
      "epoch:  65\n",
      "epoch:  66\n",
      "epoch:  67\n",
      "epoch:  68\n",
      "epoch:  69\n",
      "epoch:  70\n",
      "epoch:  71\n",
      "epoch:  72\n",
      "epoch:  73\n",
      "epoch:  74\n",
      "epoch:  75\n",
      "epoch:  76\n",
      "epoch:  77\n",
      "epoch:  78\n",
      "epoch:  79\n",
      "epoch:  80\n",
      "epoch:  81\n",
      "epoch:  82\n",
      "epoch:  83\n",
      "epoch:  84\n",
      "epoch:  85\n",
      "epoch:  86\n",
      "epoch:  87\n",
      "epoch:  88\n",
      "epoch:  89\n",
      "epoch:  90\n",
      "epoch:  91\n",
      "epoch:  92\n",
      "epoch:  93\n",
      "epoch:  94\n",
      "epoch:  95\n",
      "epoch:  96\n",
      "epoch:  97\n",
      "epoch:  98\n",
      "epoch:  99\n",
      "epoch:  100\n",
      "Epoch: 0101 cost= 0.501617501\n",
      "epoch:  101\n",
      "epoch:  102\n",
      "epoch:  103\n",
      "epoch:  104\n",
      "epoch:  105\n",
      "epoch:  106\n",
      "epoch:  107\n",
      "epoch:  108\n",
      "epoch:  109\n",
      "epoch:  110\n",
      "epoch:  111\n",
      "epoch:  112\n",
      "epoch:  113\n",
      "epoch:  114\n",
      "epoch:  115\n",
      "epoch:  116\n",
      "epoch:  117\n",
      "epoch:  118\n",
      "epoch:  119\n",
      "epoch:  120\n",
      "epoch:  121\n",
      "epoch:  122\n",
      "epoch:  123\n",
      "epoch:  124\n",
      "epoch:  125\n",
      "epoch:  126\n",
      "epoch:  127\n",
      "epoch:  128\n",
      "epoch:  129\n",
      "epoch:  130\n",
      "epoch:  131\n",
      "epoch:  132\n",
      "epoch:  133\n",
      "epoch:  134\n",
      "epoch:  135\n",
      "epoch:  136\n",
      "epoch:  137\n",
      "epoch:  138\n",
      "epoch:  139\n",
      "epoch:  140\n",
      "epoch:  141\n",
      "epoch:  142\n",
      "epoch:  143\n",
      "epoch:  144\n",
      "epoch:  145\n",
      "epoch:  146\n",
      "epoch:  147\n",
      "epoch:  148\n",
      "epoch:  149\n",
      "epoch:  150\n",
      "Epoch: 0151 cost= 0.497002896\n",
      "epoch:  151\n",
      "epoch:  152\n",
      "epoch:  153\n",
      "epoch:  154\n",
      "epoch:  155\n",
      "epoch:  156\n",
      "epoch:  157\n",
      "epoch:  158\n",
      "epoch:  159\n",
      "epoch:  160\n",
      "epoch:  161\n",
      "epoch:  162\n",
      "epoch:  163\n",
      "epoch:  164\n",
      "epoch:  165\n",
      "epoch:  166\n",
      "epoch:  167\n",
      "epoch:  168\n",
      "epoch:  169\n",
      "epoch:  170\n",
      "epoch:  171\n",
      "epoch:  172\n",
      "epoch:  173\n",
      "epoch:  174\n",
      "epoch:  175\n",
      "epoch:  176\n",
      "epoch:  177\n",
      "epoch:  178\n",
      "epoch:  179\n",
      "epoch:  180\n",
      "epoch:  181\n",
      "epoch:  182\n",
      "epoch:  183\n",
      "epoch:  184\n",
      "epoch:  185\n",
      "epoch:  186\n",
      "epoch:  187\n",
      "epoch:  188\n",
      "epoch:  189\n",
      "epoch:  190\n",
      "epoch:  191\n",
      "epoch:  192\n",
      "epoch:  193\n",
      "epoch:  194\n",
      "epoch:  195\n",
      "epoch:  196\n",
      "epoch:  197\n",
      "epoch:  198\n",
      "epoch:  199\n",
      "epoch:  200\n",
      "Epoch: 0201 cost= 0.494410045\n",
      "epoch:  201\n",
      "epoch:  202\n",
      "epoch:  203\n",
      "epoch:  204\n",
      "epoch:  205\n",
      "epoch:  206\n",
      "epoch:  207\n",
      "epoch:  208\n",
      "epoch:  209\n",
      "epoch:  210\n",
      "epoch:  211\n",
      "epoch:  212\n",
      "epoch:  213\n",
      "epoch:  214\n",
      "epoch:  215\n",
      "epoch:  216\n",
      "epoch:  217\n",
      "epoch:  218\n",
      "epoch:  219\n",
      "epoch:  220\n",
      "epoch:  221\n",
      "epoch:  222\n",
      "epoch:  223\n",
      "epoch:  224\n",
      "epoch:  225\n",
      "epoch:  226\n",
      "epoch:  227\n",
      "epoch:  228\n",
      "epoch:  229\n",
      "epoch:  230\n",
      "epoch:  231\n",
      "epoch:  232\n",
      "epoch:  233\n",
      "epoch:  234\n",
      "epoch:  235\n",
      "epoch:  236\n",
      "epoch:  237\n",
      "epoch:  238\n",
      "epoch:  239\n",
      "epoch:  240\n",
      "epoch:  241\n",
      "epoch:  242\n",
      "epoch:  243\n",
      "epoch:  244\n",
      "epoch:  245\n",
      "epoch:  246\n",
      "epoch:  247\n",
      "epoch:  248\n",
      "epoch:  249\n",
      "epoch:  250\n",
      "Epoch: 0251 cost= 0.492542006\n",
      "epoch:  251\n",
      "epoch:  252\n",
      "epoch:  253\n",
      "epoch:  254\n",
      "epoch:  255\n",
      "epoch:  256\n",
      "epoch:  257\n",
      "epoch:  258\n",
      "epoch:  259\n",
      "epoch:  260\n",
      "epoch:  261\n",
      "epoch:  262\n",
      "epoch:  263\n",
      "epoch:  264\n",
      "epoch:  265\n",
      "epoch:  266\n",
      "epoch:  267\n",
      "epoch:  268\n",
      "epoch:  269\n",
      "epoch:  270\n",
      "epoch:  271\n",
      "epoch:  272\n",
      "epoch:  273\n",
      "epoch:  274\n",
      "epoch:  275\n",
      "epoch:  276\n",
      "epoch:  277\n",
      "epoch:  278\n",
      "epoch:  279\n",
      "epoch:  280\n",
      "epoch:  281\n",
      "epoch:  282\n",
      "epoch:  283\n",
      "epoch:  284\n",
      "epoch:  285\n",
      "epoch:  286\n",
      "epoch:  287\n",
      "epoch:  288\n",
      "epoch:  289\n",
      "epoch:  290\n",
      "epoch:  291\n",
      "epoch:  292\n",
      "epoch:  293\n",
      "epoch:  294\n",
      "epoch:  295\n",
      "epoch:  296\n",
      "epoch:  297\n",
      "epoch:  298\n",
      "epoch:  299\n",
      "epoch:  300\n",
      "Epoch: 0301 cost= 0.491111842\n",
      "epoch:  301\n",
      "epoch:  302\n",
      "epoch:  303\n",
      "epoch:  304\n",
      "epoch:  305\n",
      "epoch:  306\n",
      "epoch:  307\n",
      "epoch:  308\n",
      "epoch:  309\n",
      "epoch:  310\n",
      "epoch:  311\n",
      "epoch:  312\n",
      "epoch:  313\n",
      "epoch:  314\n",
      "epoch:  315\n",
      "epoch:  316\n",
      "epoch:  317\n",
      "epoch:  318\n",
      "epoch:  319\n",
      "epoch:  320\n",
      "epoch:  321\n",
      "epoch:  322\n",
      "epoch:  323\n",
      "epoch:  324\n",
      "epoch:  325\n",
      "epoch:  326\n",
      "epoch:  327\n",
      "epoch:  328\n",
      "epoch:  329\n",
      "epoch:  330\n",
      "epoch:  331\n",
      "epoch:  332\n",
      "epoch:  333\n",
      "epoch:  334\n",
      "epoch:  335\n",
      "epoch:  336\n",
      "epoch:  337\n",
      "epoch:  338\n",
      "epoch:  339\n",
      "epoch:  340\n",
      "epoch:  341\n",
      "epoch:  342\n",
      "epoch:  343\n",
      "epoch:  344\n",
      "epoch:  345\n",
      "epoch:  346\n",
      "epoch:  347\n",
      "epoch:  348\n",
      "epoch:  349\n",
      "epoch:  350\n",
      "Epoch: 0351 cost= 0.490063053\n",
      "epoch:  351\n",
      "epoch:  352\n",
      "epoch:  353\n",
      "epoch:  354\n",
      "epoch:  355\n",
      "epoch:  356\n",
      "epoch:  357\n",
      "epoch:  358\n",
      "epoch:  359\n",
      "epoch:  360\n",
      "epoch:  361\n",
      "epoch:  362\n",
      "epoch:  363\n",
      "epoch:  364\n",
      "epoch:  365\n",
      "epoch:  366\n",
      "epoch:  367\n",
      "epoch:  368\n",
      "epoch:  369\n",
      "epoch:  370\n",
      "epoch:  371\n",
      "epoch:  372\n",
      "epoch:  373\n",
      "epoch:  374\n",
      "epoch:  375\n",
      "epoch:  376\n",
      "epoch:  377\n",
      "epoch:  378\n",
      "epoch:  379\n",
      "epoch:  380\n",
      "epoch:  381\n",
      "epoch:  382\n",
      "epoch:  383\n",
      "epoch:  384\n",
      "epoch:  385\n",
      "epoch:  386\n",
      "epoch:  387\n",
      "epoch:  388\n",
      "epoch:  389\n",
      "epoch:  390\n",
      "epoch:  391\n",
      "epoch:  392\n",
      "epoch:  393\n",
      "epoch:  394\n",
      "epoch:  395\n",
      "epoch:  396\n",
      "epoch:  397\n",
      "epoch:  398\n",
      "epoch:  399\n",
      "epoch:  400\n",
      "Epoch: 0401 cost= 0.489235671\n",
      "epoch:  401\n",
      "epoch:  402\n",
      "epoch:  403\n",
      "epoch:  404\n",
      "epoch:  405\n",
      "epoch:  406\n",
      "epoch:  407\n",
      "epoch:  408\n",
      "epoch:  409\n",
      "epoch:  410\n",
      "epoch:  411\n",
      "epoch:  412\n",
      "epoch:  413\n",
      "epoch:  414\n",
      "epoch:  415\n",
      "epoch:  416\n",
      "epoch:  417\n",
      "epoch:  418\n",
      "epoch:  419\n",
      "epoch:  420\n",
      "epoch:  421\n",
      "epoch:  422\n",
      "epoch:  423\n",
      "epoch:  424\n",
      "epoch:  425\n",
      "epoch:  426\n",
      "epoch:  427\n",
      "epoch:  428\n",
      "epoch:  429\n",
      "epoch:  430\n",
      "epoch:  431\n",
      "epoch:  432\n",
      "epoch:  433\n",
      "epoch:  434\n",
      "epoch:  435\n",
      "epoch:  436\n",
      "epoch:  437\n",
      "epoch:  438\n",
      "epoch:  439\n",
      "epoch:  440\n",
      "epoch:  441\n",
      "epoch:  442\n",
      "epoch:  443\n",
      "epoch:  444\n",
      "epoch:  445\n",
      "epoch:  446\n",
      "epoch:  447\n",
      "epoch:  448\n",
      "epoch:  449\n",
      "epoch:  450\n",
      "Epoch: 0451 cost= 0.488426965\n",
      "epoch:  451\n",
      "epoch:  452\n",
      "epoch:  453\n",
      "epoch:  454\n",
      "epoch:  455\n",
      "epoch:  456\n",
      "epoch:  457\n",
      "epoch:  458\n",
      "epoch:  459\n",
      "epoch:  460\n",
      "epoch:  461\n",
      "epoch:  462\n",
      "epoch:  463\n",
      "epoch:  464\n",
      "epoch:  465\n",
      "epoch:  466\n",
      "epoch:  467\n",
      "epoch:  468\n",
      "epoch:  469\n",
      "epoch:  470\n",
      "epoch:  471\n",
      "epoch:  472\n",
      "epoch:  473\n",
      "epoch:  474\n",
      "epoch:  475\n",
      "epoch:  476\n",
      "epoch:  477\n",
      "epoch:  478\n",
      "epoch:  479\n",
      "epoch:  480\n",
      "epoch:  481\n",
      "epoch:  482\n",
      "epoch:  483\n",
      "epoch:  484\n",
      "epoch:  485\n",
      "epoch:  486\n",
      "epoch:  487\n",
      "epoch:  488\n",
      "epoch:  489\n",
      "epoch:  490\n",
      "epoch:  491\n",
      "epoch:  492\n",
      "epoch:  493\n",
      "epoch:  494\n",
      "epoch:  495\n",
      "epoch:  496\n",
      "epoch:  497\n",
      "epoch:  498\n",
      "epoch:  499\n",
      "epoch:  500\n",
      "Epoch: 0501 cost= 0.487760619\n",
      "epoch:  501\n",
      "epoch:  502\n",
      "epoch:  503\n",
      "epoch:  504\n",
      "epoch:  505\n",
      "epoch:  506\n",
      "epoch:  507\n",
      "epoch:  508\n",
      "epoch:  509\n",
      "epoch:  510\n",
      "epoch:  511\n",
      "epoch:  512\n",
      "epoch:  513\n",
      "epoch:  514\n",
      "epoch:  515\n",
      "epoch:  516\n",
      "epoch:  517\n",
      "epoch:  518\n",
      "epoch:  519\n",
      "epoch:  520\n",
      "epoch:  521\n",
      "epoch:  522\n",
      "epoch:  523\n",
      "epoch:  524\n",
      "epoch:  525\n",
      "epoch:  526\n",
      "epoch:  527\n",
      "epoch:  528\n",
      "epoch:  529\n",
      "epoch:  530\n",
      "epoch:  531\n",
      "epoch:  532\n",
      "epoch:  533\n",
      "epoch:  534\n",
      "epoch:  535\n",
      "epoch:  536\n",
      "epoch:  537\n",
      "epoch:  538\n",
      "epoch:  539\n",
      "epoch:  540\n",
      "epoch:  541\n",
      "epoch:  542\n",
      "epoch:  543\n",
      "epoch:  544\n",
      "epoch:  545\n",
      "epoch:  546\n",
      "epoch:  547\n",
      "epoch:  548\n",
      "epoch:  549\n",
      "epoch:  550\n",
      "Epoch: 0551 cost= 0.487121147\n",
      "epoch:  551\n",
      "epoch:  552\n",
      "epoch:  553\n",
      "epoch:  554\n",
      "epoch:  555\n",
      "epoch:  556\n",
      "epoch:  557\n",
      "epoch:  558\n",
      "epoch:  559\n",
      "epoch:  560\n",
      "epoch:  561\n",
      "epoch:  562\n",
      "epoch:  563\n",
      "epoch:  564\n",
      "epoch:  565\n",
      "epoch:  566\n",
      "epoch:  567\n",
      "epoch:  568\n",
      "epoch:  569\n",
      "epoch:  570\n",
      "epoch:  571\n",
      "epoch:  572\n",
      "epoch:  573\n",
      "epoch:  574\n",
      "epoch:  575\n",
      "epoch:  576\n",
      "epoch:  577\n",
      "epoch:  578\n",
      "epoch:  579\n",
      "epoch:  580\n",
      "epoch:  581\n",
      "epoch:  582\n",
      "epoch:  583\n",
      "epoch:  584\n",
      "epoch:  585\n",
      "epoch:  586\n",
      "epoch:  587\n",
      "epoch:  588\n",
      "epoch:  589\n",
      "epoch:  590\n",
      "epoch:  591\n",
      "epoch:  592\n",
      "epoch:  593\n",
      "epoch:  594\n",
      "epoch:  595\n",
      "epoch:  596\n",
      "epoch:  597\n",
      "epoch:  598\n",
      "epoch:  599\n",
      "epoch:  600\n",
      "Epoch: 0601 cost= 0.486525784\n",
      "epoch:  601\n",
      "epoch:  602\n",
      "epoch:  603\n",
      "epoch:  604\n",
      "epoch:  605\n",
      "epoch:  606\n",
      "epoch:  607\n",
      "epoch:  608\n",
      "epoch:  609\n",
      "epoch:  610\n",
      "epoch:  611\n",
      "epoch:  612\n",
      "epoch:  613\n",
      "epoch:  614\n",
      "epoch:  615\n",
      "epoch:  616\n",
      "epoch:  617\n",
      "epoch:  618\n",
      "epoch:  619\n",
      "epoch:  620\n",
      "epoch:  621\n",
      "epoch:  622\n",
      "epoch:  623\n",
      "epoch:  624\n",
      "epoch:  625\n",
      "epoch:  626\n",
      "epoch:  627\n",
      "epoch:  628\n",
      "epoch:  629\n",
      "epoch:  630\n",
      "epoch:  631\n",
      "epoch:  632\n",
      "epoch:  633\n",
      "epoch:  634\n",
      "epoch:  635\n",
      "epoch:  636\n",
      "epoch:  637\n",
      "epoch:  638\n",
      "epoch:  639\n",
      "epoch:  640\n",
      "epoch:  641\n",
      "epoch:  642\n",
      "epoch:  643\n",
      "epoch:  644\n",
      "epoch:  645\n",
      "epoch:  646\n",
      "epoch:  647\n",
      "epoch:  648\n",
      "epoch:  649\n",
      "epoch:  650\n",
      "Epoch: 0651 cost= 0.485988100\n",
      "epoch:  651\n",
      "epoch:  652\n",
      "epoch:  653\n",
      "epoch:  654\n",
      "epoch:  655\n",
      "epoch:  656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  657\n",
      "epoch:  658\n",
      "epoch:  659\n",
      "epoch:  660\n",
      "epoch:  661\n",
      "epoch:  662\n",
      "epoch:  663\n",
      "epoch:  664\n",
      "epoch:  665\n",
      "epoch:  666\n",
      "epoch:  667\n",
      "epoch:  668\n",
      "epoch:  669\n",
      "epoch:  670\n",
      "epoch:  671\n",
      "epoch:  672\n",
      "epoch:  673\n",
      "epoch:  674\n",
      "epoch:  675\n",
      "epoch:  676\n",
      "epoch:  677\n",
      "epoch:  678\n",
      "epoch:  679\n",
      "epoch:  680\n",
      "epoch:  681\n",
      "epoch:  682\n",
      "epoch:  683\n",
      "epoch:  684\n",
      "epoch:  685\n",
      "epoch:  686\n",
      "epoch:  687\n",
      "epoch:  688\n",
      "epoch:  689\n",
      "epoch:  690\n",
      "epoch:  691\n",
      "epoch:  692\n",
      "epoch:  693\n",
      "epoch:  694\n",
      "epoch:  695\n",
      "epoch:  696\n",
      "epoch:  697\n",
      "epoch:  698\n",
      "epoch:  699\n",
      "epoch:  700\n",
      "Epoch: 0701 cost= 0.485473974\n",
      "epoch:  701\n",
      "epoch:  702\n",
      "epoch:  703\n",
      "epoch:  704\n",
      "epoch:  705\n",
      "epoch:  706\n",
      "epoch:  707\n",
      "epoch:  708\n",
      "epoch:  709\n",
      "epoch:  710\n",
      "epoch:  711\n",
      "epoch:  712\n",
      "epoch:  713\n",
      "epoch:  714\n",
      "epoch:  715\n",
      "epoch:  716\n",
      "epoch:  717\n",
      "epoch:  718\n",
      "epoch:  719\n",
      "epoch:  720\n",
      "epoch:  721\n",
      "epoch:  722\n",
      "epoch:  723\n",
      "epoch:  724\n",
      "epoch:  725\n",
      "epoch:  726\n",
      "epoch:  727\n",
      "epoch:  728\n",
      "epoch:  729\n",
      "epoch:  730\n",
      "epoch:  731\n",
      "epoch:  732\n",
      "epoch:  733\n",
      "epoch:  734\n",
      "epoch:  735\n",
      "epoch:  736\n",
      "epoch:  737\n",
      "epoch:  738\n",
      "epoch:  739\n",
      "epoch:  740\n",
      "epoch:  741\n",
      "epoch:  742\n",
      "epoch:  743\n",
      "epoch:  744\n",
      "epoch:  745\n",
      "epoch:  746\n",
      "epoch:  747\n",
      "epoch:  748\n",
      "epoch:  749\n",
      "epoch:  750\n",
      "Epoch: 0751 cost= 0.484951274\n",
      "epoch:  751\n",
      "epoch:  752\n",
      "epoch:  753\n",
      "epoch:  754\n",
      "epoch:  755\n",
      "epoch:  756\n",
      "epoch:  757\n",
      "epoch:  758\n",
      "epoch:  759\n",
      "epoch:  760\n",
      "epoch:  761\n",
      "epoch:  762\n",
      "epoch:  763\n",
      "epoch:  764\n",
      "epoch:  765\n",
      "epoch:  766\n",
      "epoch:  767\n",
      "epoch:  768\n",
      "epoch:  769\n",
      "epoch:  770\n",
      "epoch:  771\n",
      "epoch:  772\n",
      "epoch:  773\n",
      "epoch:  774\n",
      "epoch:  775\n",
      "epoch:  776\n",
      "epoch:  777\n",
      "epoch:  778\n",
      "epoch:  779\n",
      "epoch:  780\n",
      "epoch:  781\n",
      "epoch:  782\n",
      "epoch:  783\n",
      "epoch:  784\n",
      "epoch:  785\n",
      "epoch:  786\n",
      "epoch:  787\n",
      "epoch:  788\n",
      "epoch:  789\n",
      "epoch:  790\n",
      "epoch:  791\n",
      "epoch:  792\n",
      "epoch:  793\n",
      "epoch:  794\n",
      "epoch:  795\n",
      "epoch:  796\n",
      "epoch:  797\n",
      "epoch:  798\n",
      "epoch:  799\n",
      "epoch:  800\n",
      "Epoch: 0801 cost= 0.484441159\n",
      "epoch:  801\n",
      "epoch:  802\n",
      "epoch:  803\n",
      "epoch:  804\n",
      "epoch:  805\n",
      "epoch:  806\n",
      "epoch:  807\n",
      "epoch:  808\n",
      "epoch:  809\n",
      "epoch:  810\n",
      "epoch:  811\n",
      "epoch:  812\n",
      "epoch:  813\n",
      "epoch:  814\n",
      "epoch:  815\n",
      "epoch:  816\n",
      "epoch:  817\n",
      "epoch:  818\n",
      "epoch:  819\n",
      "epoch:  820\n",
      "epoch:  821\n",
      "epoch:  822\n",
      "epoch:  823\n",
      "epoch:  824\n",
      "epoch:  825\n",
      "epoch:  826\n",
      "epoch:  827\n",
      "epoch:  828\n",
      "epoch:  829\n",
      "epoch:  830\n",
      "epoch:  831\n",
      "epoch:  832\n",
      "epoch:  833\n",
      "epoch:  834\n",
      "epoch:  835\n",
      "epoch:  836\n",
      "epoch:  837\n",
      "epoch:  838\n",
      "epoch:  839\n",
      "epoch:  840\n",
      "epoch:  841\n",
      "epoch:  842\n",
      "epoch:  843\n",
      "epoch:  844\n",
      "epoch:  845\n",
      "epoch:  846\n",
      "epoch:  847\n",
      "epoch:  848\n",
      "epoch:  849\n",
      "epoch:  850\n",
      "Epoch: 0851 cost= 0.483960560\n",
      "epoch:  851\n",
      "epoch:  852\n",
      "epoch:  853\n",
      "epoch:  854\n",
      "epoch:  855\n",
      "epoch:  856\n",
      "epoch:  857\n",
      "epoch:  858\n",
      "epoch:  859\n",
      "epoch:  860\n",
      "epoch:  861\n",
      "epoch:  862\n",
      "epoch:  863\n",
      "epoch:  864\n",
      "epoch:  865\n",
      "epoch:  866\n",
      "epoch:  867\n",
      "epoch:  868\n",
      "epoch:  869\n",
      "epoch:  870\n",
      "epoch:  871\n",
      "epoch:  872\n",
      "epoch:  873\n",
      "epoch:  874\n",
      "epoch:  875\n",
      "epoch:  876\n",
      "epoch:  877\n",
      "epoch:  878\n",
      "epoch:  879\n",
      "epoch:  880\n",
      "epoch:  881\n",
      "epoch:  882\n",
      "epoch:  883\n",
      "epoch:  884\n",
      "epoch:  885\n",
      "epoch:  886\n",
      "epoch:  887\n",
      "epoch:  888\n",
      "epoch:  889\n",
      "epoch:  890\n",
      "epoch:  891\n",
      "epoch:  892\n",
      "epoch:  893\n",
      "epoch:  894\n",
      "epoch:  895\n",
      "epoch:  896\n",
      "epoch:  897\n",
      "epoch:  898\n",
      "epoch:  899\n",
      "epoch:  900\n",
      "Epoch: 0901 cost= 0.483501964\n",
      "epoch:  901\n",
      "epoch:  902\n",
      "epoch:  903\n",
      "epoch:  904\n",
      "epoch:  905\n",
      "epoch:  906\n",
      "epoch:  907\n",
      "epoch:  908\n",
      "epoch:  909\n",
      "epoch:  910\n",
      "epoch:  911\n",
      "epoch:  912\n",
      "epoch:  913\n",
      "epoch:  914\n",
      "epoch:  915\n",
      "epoch:  916\n",
      "epoch:  917\n",
      "epoch:  918\n",
      "epoch:  919\n",
      "epoch:  920\n",
      "epoch:  921\n",
      "epoch:  922\n",
      "epoch:  923\n",
      "epoch:  924\n",
      "epoch:  925\n",
      "epoch:  926\n",
      "epoch:  927\n",
      "epoch:  928\n",
      "epoch:  929\n",
      "epoch:  930\n",
      "epoch:  931\n",
      "epoch:  932\n",
      "epoch:  933\n",
      "epoch:  934\n",
      "epoch:  935\n",
      "epoch:  936\n",
      "epoch:  937\n",
      "epoch:  938\n",
      "epoch:  939\n",
      "epoch:  940\n",
      "epoch:  941\n",
      "epoch:  942\n",
      "epoch:  943\n",
      "epoch:  944\n",
      "epoch:  945\n",
      "epoch:  946\n",
      "epoch:  947\n",
      "epoch:  948\n",
      "epoch:  949\n",
      "epoch:  950\n",
      "Epoch: 0951 cost= 0.483060713\n",
      "epoch:  951\n",
      "epoch:  952\n",
      "epoch:  953\n",
      "epoch:  954\n",
      "epoch:  955\n",
      "epoch:  956\n",
      "epoch:  957\n",
      "epoch:  958\n",
      "epoch:  959\n",
      "epoch:  960\n",
      "epoch:  961\n",
      "epoch:  962\n",
      "epoch:  963\n",
      "epoch:  964\n",
      "epoch:  965\n",
      "epoch:  966\n",
      "epoch:  967\n",
      "epoch:  968\n",
      "epoch:  969\n",
      "epoch:  970\n",
      "epoch:  971\n",
      "epoch:  972\n",
      "epoch:  973\n",
      "epoch:  974\n",
      "epoch:  975\n",
      "epoch:  976\n",
      "epoch:  977\n",
      "epoch:  978\n",
      "epoch:  979\n",
      "epoch:  980\n",
      "epoch:  981\n",
      "epoch:  982\n",
      "epoch:  983\n",
      "epoch:  984\n",
      "epoch:  985\n",
      "epoch:  986\n",
      "epoch:  987\n",
      "epoch:  988\n",
      "epoch:  989\n",
      "epoch:  990\n",
      "epoch:  991\n",
      "epoch:  992\n",
      "epoch:  993\n",
      "epoch:  994\n",
      "epoch:  995\n",
      "epoch:  996\n",
      "epoch:  997\n",
      "epoch:  998\n",
      "epoch:  999\n",
      "Optimization Finished!\n",
      "Accuracy: 0.74281883\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        print (\"epoch: \", epoch)\n",
    "        avg_cost = 0.0\n",
    "        total_batch = int(len(train_x) / batch_size)\n",
    "        x_batches = np.array_split(train_x, total_batch)\n",
    "        y_batches = np.array_split(train_y, total_batch)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = x_batches[i], y_batches[i]\n",
    "            _, c = sess.run([optimizer, cost], \n",
    "                            feed_dict={\n",
    "                                x: batch_x, \n",
    "                                y: batch_y \n",
    "                            })\n",
    "            avg_cost += c / total_batch\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \\\n",
    "                \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "    correct_prediction = tf.equal(tf.argmax(predictions, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: test_x, y: test_y}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: The project helped in exploring different natural language processing techniques that can be used to extract semantics out of a given sentence. The accuracy achieved by the model on test data is around 74%. To further increase the accuracy we can \n",
    "\n",
    "### 1) Add some more features \n",
    "### 2) We can use cross validation to expose our model to different types of sentence structures\n",
    "### 3) Increase the depth of the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
